# Estimo---Automation-Project-

## ğŸ¯ Objectif du projet
Ce projet vise Ã  construire une **infrastructure de data automation & deployment** complÃ¨te, basÃ©e sur une stack open-source et gratuite.  
Lâ€™objectif est de dÃ©montrer la capacitÃ© Ã  :
- Dockeriser des services (API, Airflow, Monitoring),
- Automatiser les traitements avec Airflow,
- Monitorer les performances via Prometheus & Grafana,
- Et dÃ©ployer lâ€™ensemble sur Kubernetes.

---

## ğŸ“ Arborescence du dÃ©pÃ´t
frontend/              â†’ Landing page ou interface utilisateur simple
api/                   â†’ API Flask/FastAPI (accÃ¨s aux donnÃ©es ou prÃ©dictions)
db/                    â†’ Scripts SQL & jeux de donnÃ©es (CSV)
â”œâ”€ sql/
â””â”€ csv/
airflow/               â†’ DAGs dâ€™orchestration
â”œâ”€ dags/
â””â”€ plugins/
monitoring/            â†’ Stack Prometheus + Grafana
â”œâ”€ prometheus/
â””â”€ grafana/
k8s/                   â†’ Manifests Kubernetes (dÃ©ploiement, services, monitoring)
docs/                  â†’ Documentation, schÃ©mas, livrables & preuves
â””â”€ img/

---

## ğŸ“¦ Livrables attendus (pÃ©rimÃ¨tre jury)

| Livrable | Description | Preuve (DoD) |
|-----------|--------------|---------------|
| **Dockerisation complÃ¨te** | Tous les composants (API, Airflow, Prometheus, Grafana) sont containerisÃ©s et exÃ©cutables ensemble. | `docker-compose.yml` + captures des conteneurs en cours dâ€™exÃ©cution. |
| **Orchestration Airflow** | Un DAG fonctionnel planifie et exÃ©cute les tÃ¢ches dâ€™ingestion ou de traitement. | Capture de lâ€™interface Airflow avec le DAG en â€œsuccessâ€. |
| **Monitoring Grafana** | Dashboards connectÃ©s Ã  Prometheus pour suivre les mÃ©triques systÃ¨me et applicatives. | Capture dâ€™Ã©cran dâ€™un dashboard Grafana opÃ©rationnel. |
| **DÃ©ploiement Kubernetes** | Manifests et ressources pour exÃ©cuter les services dans un cluster (minikube, kind ou autre). | Fichiers `.yaml` + preuve de `kubectl get pods`. |
| **Benchmarks** | Ã‰valuation de la performance et de la scalabilitÃ© (temps dâ€™exÃ©cution, CPU/RAM, latence). | Tableau de rÃ©sultats + graphique des performances. |
| **VidÃ©o dÃ©mo** | Courte dÃ©monstration montrant le pipeline complet en action. | Lien vers la vidÃ©o (YouTube ou fichier). |
| **Documentation** | Description technique, architecture, stack, limitations et suites possibles. | Ce dÃ©pÃ´t + fichiers `docs/README.md` et schÃ©mas. |

---

## ğŸ§© Stack technique
| Domaine | Outil / Technologie | Justification |
|----------|--------------------|----------------|
| **Conteneurisation** | Docker | Standard de packaging, portable et simple Ã  exÃ©cuter. |
| **Orchestration de tÃ¢ches** | Apache Airflow | Orchestrateur open-source, trÃ¨s utilisÃ© en data engineering. |
| **Monitoring** | Prometheus + Grafana | Duo open-source complet pour collecter et visualiser les mÃ©triques. |
| **Base de donnÃ©es** | SQLite / PostgreSQL | Facile Ã  dÃ©ployer localement et compatible avec Airflow. |
| **DÃ©ploiement** | Kubernetes (minikube / kind) | Standard de dÃ©ploiement cloud-native, requis pour le livrable final. |

---

## ğŸ§± Plan dâ€™architecture
Voici le schÃ©ma global du projet (format image) ğŸ‘‡  

ğŸ“· **Diagramme dâ€™architecture (PNG)**  
<img width="3840" height="2175" alt="Untitled diagram _ Mermaid Chart-2025-10-06-153437" src="https://github.com/user-attachments/assets/710e42c1-193b-4975-8e6d-042b2cb66209" />


 Stack Technique â€“ Projet 
Estimo
ğŸ¯ Objectif
Concevoir une infrastructure de donnÃ©es complÃ¨te, containerisÃ©e et orchestrÃ©e, capable de :
collecter et agrÃ©ger des donnÃ©es publiques immobiliÃ¨res (DVF, indicateurs communaux) ;


exposer un service dâ€™estimation simple et transparent ;


surveiller et automatiser les traitements via des outils professionnels open-source.


Toute la stack repose sur des composants gratuits et open-source, dÃ©ployables en local ou sur un cluster Kubernetes.

ğŸ§© Vue dâ€™ensemble
Lâ€™architecture Estimo sâ€™appuie sur 6 briques principales :

Domaine
Technologie
RÃ´le clÃ©
Frontend
Nginx
Sert la landing page statique du simulateur
Backend / API
FastAPI (Python)
Service REST qui calcule les estimations
Base de donnÃ©es
PostgreSQL
Stockage unique des donnÃ©es marchÃ© et utilisateurs
Orchestration / Automatisation
Apache Airflow
Planifie et exÃ©cute les traitements de donnÃ©es (ingestion DVF, agrÃ©gats, snapshots)
Monitoring / ObservabilitÃ©
Prometheus + Grafana
Collecte et visualisation des mÃ©triques systÃ¨me et applicatives
Conteneurisation / DÃ©ploiement
Docker + Kubernetes (k3d)
Encapsulation, orchestration et scalabilitÃ© du projet
CI/CD & Outils de support
GitHub Actions + DBeaver (+ n8n optionnel)
IntÃ©gration continue, exploration BD, automatisations lÃ©gÃ¨res


ğŸ§  
Justification dÃ©taillÃ©e des choix
1ï¸âƒ£ Frontend â€“ Nginx
RÃ´le : hÃ©berger une simple landing page statique contenant le formulaire dâ€™estimation (HTML/CSS/JS).


Pourquoi ce choix ?


LÃ©ger, stable, et natif dans Docker.


Aucun framework JS nÃ©cessaire (Next/Vite non indispensables pour le MVP).


Requiert trÃ¨s peu de ressources.


Livrable attendu : dÃ©monstration visuelle du simulateur et connexion Ã  lâ€™API.



2ï¸âƒ£ Backend â€“ FastAPI (Python)
RÃ´le : cÅ“ur du projet. Lâ€™API reÃ§oit les entrÃ©es utilisateur et calcule :


la valeur estimÃ©e du bien (median_price_m2 Ã— surface) ;


la catÃ©gorie (Sous / Dans / Au-dessus du marchÃ©).


Pourquoi FastAPI ?


Performant et minimaliste, adaptÃ© aux APIs data-driven.


Auto-documentation Swagger â†’ facilite la dÃ©mo au jury.


IntÃ©gration native avec pandas, NumPy et scikit-learn (utile pour la phase ML).


RÃ©sultat attendu : un endpoint /estimate fonctionnel, mesurable en latence et exactitude.



3ï¸âƒ£ Base de donnÃ©es â€“ PostgreSQL
RÃ´le : stockage unique et central des trois univers de donnÃ©es :


DVF gÃ©olocalisÃ©e (transactions rÃ©elles nettoyÃ©es) ;


Indicateurs communaux (agrÃ©gats 2014â€“2024) ;


EntrÃ©es utilisateurs (estimations rÃ©alisÃ©es depuis le site).


Pourquoi Postgres ?


GÃ¨re les agrÃ©gats statistiques (percentiles, mÃ©dianes) nÃ©cessaires Ã  la table market_stats.


Solide, open-source, compatible SQL standard, et exploitable via DBeaver.


Peut hÃ©berger toutes les tables du star schema (dim/fact) dans un seul schÃ©ma logique.


Utilisation prÃ©vue :


Base â€œvÃ©ritÃ© marchÃ©â€ : market_stats, communes_market_yearly.


Base â€œutilisateursâ€ : estimation_input, fact_estimation.



4ï¸âƒ£ Orchestration â€“ Apache Airflow
RÃ´le : automatiser les tÃ¢ches de prÃ©paration de donnÃ©es.


DAG #1 : ingestion et nettoyage du fichier DVF gÃ©olocalisÃ©.


DAG #2 : calcul des statistiques marchÃ© (mÃ©dianes/p25/p75 par zone).


DAG #3 : mise Ã  jour des agrÃ©gats communaux.


Pourquoi Airflow ?


MentionnÃ© explicitement dans la consigne (â€œAirflow DAG orchestrationâ€).


Standard industriel open-source pour le scheduling et la traÃ§abilitÃ©.


Interface claire pour le jury (exÃ©cution DAG visible en web UI).


Alternative complÃ©mentaire : n8n peut automatiser des notifications (alertes Slack, envoi email) mais ne remplace pas Airflow.



5ï¸âƒ£ Monitoring â€“ Prometheus + Grafana
RÃ´le : surveiller la santÃ© de lâ€™infrastructure et les KPIs mÃ©tiers.


Prometheus collecte les mÃ©triques (API, Airflow, PostgreSQL).


Grafana les affiche dans deux dashboards :


Technique : CPU, mÃ©moire, latence, erreurs 4xx/5xx, uptime.


MÃ©tier : nb dâ€™estimations, rÃ©partition Sous/Dans/Au-dessus, volumes DVF traitÃ©s.


Pourquoi ce duo ?

Exigence explicite du sujet (â€œGrafana monitoring dashboardâ€).

Standard open-source universel, facile Ã  dockeriser et Ã  configurer.

Livrable attendu : un dashboard Grafana provisionnÃ© accessible via le cluster.

6ï¸âƒ£ Conteneurisation & DÃ©ploiement â€“ Docker + Kubernetes (k3d/kind)
RÃ´le : uniformiser lâ€™environnement de dev, puis dÃ©montrer le dÃ©ploiement distribuÃ©.

Pourquoi Docker Compose ?
SimplicitÃ© pour le dÃ©veloppement local et la dÃ©mo initiale : une seule commande docker compose up.

Pourquoi Kubernetes (k3d ou kind) ?
NÃ©cessitÃ© du livrable â€œKubernetes deploymentâ€.

Ces distributions locales sont gratuites et fonctionnent sur tout poste.
Elles permettent de montrer le kubectl get pods et lâ€™Ingress fonctionnel (preuve dâ€™orchestration).


Ingress : Traefik ou NGINX Ingress (un seul pour la dÃ©mo).
Packaging : Helm pour dÃ©ploiement modulaire (API, Airflow, Grafana).

RÃ©sultat attendu : cluster opÃ©rationnel et reproductible.



7ï¸âƒ£ 
CI/CD â€“ GitHub Actions
RÃ´le : automatiser la construction et la livraison des images Docker.


Pourquoi ce choix ?
Gratuit, directement intÃ©grÃ© Ã  GitHub.
Permet de valider le build, lancer les tests, et pousser les images dans un registre (GHCR ou Docker Hub).

Pipeline prÃ©vu :

Job 1 : lint + test API.

Job 2 : build/push des images.

Job 3 : (optionnel) dÃ©ploiement automatique sur k3d.

8ï¸âƒ£ Outils de support
DBeaver â†’ client SQL pour explorer Postgres et valider les requÃªtes.
Raison : outil gratuit, multiplateforme, intuitif pour montrer les tables market_stats, fact_estimation pendant la soutenance.

n8n (optionnel) â†’ automatisation visuelle (alertes DAG, notifications).
Raison : complÃ©ment ergonomique Ã  Airflow pour des automatisations â€œlÃ©gÃ¨resâ€ (non data).

Make / scripts bash â†’ pour lancer des benchmarks locaux.
wrk ou k6 â†’ pour mesurer la latence API (preuve de performance).



ğŸ” Principes de sÃ©curitÃ© et conformitÃ©
Aucune donnÃ©e personnelle conservÃ©e (adresses anonymisÃ©es â†’ zone_key commune).

AccÃ¨s Ã  la base protÃ©gÃ©s par variables dâ€™environnement / secrets Kubernetes.

Pas de services exposÃ©s en public hormis lâ€™API via ingress.

Estimo â€“ Simulateur de Valeur ImmobiliÃ¨re

ğŸ¯ Vision
Estimo est une plateforme simple et accessible qui permet Ã  nâ€™importe quel utilisateur dâ€™obtenir une estimation instantanÃ©e de la valeur de son bien immobilier sur le marchÃ©.
Lâ€™objectif est double :
Informer le grand public avec une estimation fiable et comprÃ©hensible.


Constituer une base de donnÃ©es riche pour affiner nos modÃ¨les de prÃ©diction Ã  partir de transactions rÃ©elles.



ğŸ’¡ ProblÃ©matique
Aujourdâ€™hui, beaucoup de propriÃ©taires ou dâ€™acheteurs ne savent pas si un prix de vente est au-dessus ou en dessous du marchÃ© rÃ©el.
Les simulateurs existants sont souvent :
opaques (peu dâ€™explications sur le calcul),

limitÃ©s (peu de critÃ¨res pris en compte),
fermÃ©s (aucune ouverture des donnÃ©es).
Estimo veut rendre lâ€™estimation immobiliÃ¨re transparente, Ã©ducative et Ã©volutive.

ğŸ§© Concept
Une landing page (page web simple et claire) permet de renseigner les caractÃ©ristiques dâ€™un bien :
Localisation (adresse, code postal, commune)

Surface habitable
Nombre de piÃ¨ces / chambres / salles de bain
AnnÃ©e de construction ou anciennetÃ©
Type de logement (maison, appartementâ€¦)
Ã‰tiquette Ã©nergÃ©tique (DPE)
Autres atouts (balcon, parking, jardinâ€¦)

â†’ En un clic, le visiteur obtient :
une estimation du prix de marchÃ© (avec une fourchette),

un indice de positionnement :

 ğŸ”µ Sous le marchÃ© / ğŸŸ¢ Dans le marchÃ© / ğŸ”´ Au-dessus du marchÃ©,

une courte analyse expliquant les facteurs principaux (surface, zone, Ã©tat, DPEâ€¦).

ğŸ§  Valeur ajoutÃ©e
Pour lâ€™utilisateur : vision claire, intuitive, et sans jargon.

Pour nous (techniquement) : les donnÃ©es collectÃ©es (anonymisÃ©es) alimentent une base dâ€™apprentissage pour entraÃ®ner Ã  terme un modÃ¨le de Machine Learning capable de prÃ©dire les prix de maniÃ¨re plus fine (type AVM â€“ Automated Valuation Model).


ğŸ“Š Sources de donnÃ©es
Nous nous appuierons sur des bases publiques fiables :
DVF / DVF+ : base nationale des transactions immobiliÃ¨res (prix, surfaces, localisation).


INSEE / BAN / DPE : informations gÃ©ographiques, dÃ©mographiques et Ã©nergÃ©tiques.


Ces donnÃ©es servent de rÃ©fÃ©rentiel de marchÃ© pour comparer les biens soumis par les utilisateurs.

ğŸ” Positionnement
Estimo nâ€™est pas une agence ni un site dâ€™annonces.
Câ€™est un simulateur indÃ©pendant, fondÃ© sur la donnÃ©e et la transparence.
Le but : dÃ©mocratiser la data immobiliÃ¨re tout en prÃ©parant une infrastructure scalable (Docker + API + Data pipeline).

ğŸš€ Ã‰tapes futures
Phase 1 â€“ Landing page et API de simulation

 â†’ capturer les entrÃ©es, retourner une estimation simple (basÃ©e sur statistiques locales).

Phase 2 â€“ Base de donnÃ©es nationale + pipeline de nettoyage

 â†’ construire les tables de rÃ©fÃ©rence du marchÃ©.

Phase 3 â€“ Machine Learning

â†’ entraÃ®ner un modÃ¨le de prÃ©diction (prix/mÂ²) sur DVF + variables gÃ©ographiques.

Phase 4 â€“ Monitoring et dashboard

 â†’ observer la qualitÃ© des estimations, performance et usage.






RGPD : donnÃ©es strictement agrÃ©gÃ©es, aucune PII.

